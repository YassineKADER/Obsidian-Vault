# **Table des mati√®res**

Table des mati√®res

Cahier de Charges - Analyse de March√© avec Donn√©es Massives

Objectif:

√âtapes du projet:

Livrables Attendus:

Contraintes Techniques:

Calendrier et √âch√©ances:

Notes Suppl√©mentaires:

Collecting & Cleaning:

Data Collecting:

Cleaning And Formatting:

Slicing et creation des tables fait et des tables des tables de dimensions:

Model Mixte:

Data Slicing:

Reporting & Visualization:

Visualization:

OLAP

# Cahier de Charges - Analyse de March√© avec Donn√©es Massives

## Objectif:

Le projet vise √† analyser le march√© en utilisant une grande quantit√© de donn√©es sur les ventes. Les donn√©es comprennent les colonnes suivantes: ['Order_ID','Order_Date','Ship_Date','Ship_Mode','Customer_ID','Customer_Name','Segment','Country','City','State','Postal_Code','Region','Product_ID','Category','Sub-Category','Product_Name','Sales','Quantity','Discount','Profit']

## √âtapes du projet:

1. **Collecte de Donn√©es:**
    - Les donn√©es sont stock√©es dans des fichiers CSV distincts pour chaque table:
        - customers.csv (clients)
        - orders.csv (commandes)
        - dates.csv (dates)
        - products.csv (produits)
        - categories.csv (cat√©gories)
        - subcategories.csv (sous-cat√©gories)
        - locations.csv (emplacements)
2. **Pr√©traitement des Donn√©es:**
    - Charger les fichiers CSV dans des DataFrames (par exemple, pandas en Python, Pentaho DI).
    - V√©rifier la qualit√© des donn√©es (valeurs manquantes, erreurs, duplications, etc.).
    - Nettoyer et transformer les donn√©es au besoin (formatage des dates, suppression des doublons, etc.).
3. **Cr√©ation d'un Mod√®le de Donn√©es:**
    - Concevoir un sch√©ma de base de donn√©es mixte pour le data warehouse.
    - Identifier les entit√©s, les attributs et les relations entre les tables.
    - Utiliser des cl√©s primaires et √©trang√®res pour lier les tables entre elles.
4. **Chargement des Donn√©es dans le Data Warehouse:**
    - Cr√©er une base de donn√©es relationnelle (par exemple, MySQL, PostgreSQL).
    - Concevoir des scripts SQL pour cr√©er les tables selon le mod√®le d√©fini.
    - Charger les donn√©es des fichiers CSV dans les tables correspondantes.
5. **Analyse de March√©:**
    - R√©aliser des requ√™tes SQL pour extraire des informations pertinentes:
        - Analyser les ventes par segment de client, par pays, par ville, etc.
        - Examiner les tendances temporelles des ventes (mensuelles, annuelles).
        - Identifier les produits les plus vendus, les cat√©gories les plus lucratives, etc.
        - √âvaluer la rentabilit√© des ventes en fonction des discounts appliqu√©s.
6. **Visualisation des Donn√©es:**
    - Utiliser des outils de visualisation (comme matplotlib, seaborn, Tableau, Power BI) pour cr√©er des graphiques et des tableaux de bord.
    - Pr√©senter les r√©sultats de mani√®re claire et concise pour faciliter la compr√©hension et la prise de d√©cision.

## Livrables Attendus:

1. Sch√©ma du Data Warehouse:
    - Diagramme entit√©-relation (ER) montrant la structure des tables et leurs relations.
2. Code Source:
    - Scripts Python pour le pr√©traitement des donn√©es et le chargement dans la base de donn√©es.
    - Scripts SQL pour la cr√©ation des tables et l'analyse des donn√©es.
3. Rapport d'Analyse:
    - Rapport d√©taill√© sur les r√©sultats de l'analyse de march√©.
    - Graphiques, tableaux et conclusions sur les tendances et les insights d√©couverts.
4. Tableau de Bord Interactif (en option):
    - Si n√©cessaire, cr√©er un tableau de bord interactif pour visualiser les donn√©es cl√©s.

## Contraintes Techniques:

- Utiliser des technologies open source et largement utilis√©es (Python, pandas, SQL).
- Assurer la s√©curit√© et la confidentialit√© des donn√©es pendant tout le processus.

## Calendrier et √âch√©ances:

- **Date de d√©but:** [Date de d√©but du projet]
- **Date de fin:** [Date de fin du projet]
- **√âch√©ances interm√©diaires:** D√©finir des dates limites pour chaque √©tape du projet.

## Notes Suppl√©mentaires:

- Le respect des bonnes pratiques en mati√®re de gestion de projet et d'analyse de donn√©es est crucial.
- La collaboration √©troite entre les √©quipes technique, analytique et de gestion est recommand√©e pour garantir le succ√®s du projet.

# Collecting & Cleaning:

Voici les d√©tails sur les colonnes et un exemple de donn√©es fourni :

- **Order_ID** : Identifiant unique pour chaque commande.
- **Order_Date** : Date √† laquelle la commande a √©t√© pass√©e.
- **Ship_Date** : Date √† laquelle la commande a √©t√© exp√©di√©e.
- **Ship_Mode** : Mode d'exp√©dition de la commande (par exemple, Standard, Express, etc.).
- **Customer_ID** : Identifiant unique pour chaque client.
- **Customer_Name** : Nom du client.
- **Segment** : Segment de march√© auquel le client appartient (par exemple, Entreprise, Consommateur, etc.).
- **Country** : Pays o√π la commande a √©t√© pass√©e.
- **City** : Ville o√π la commande a √©t√© pass√©e.
- **State** : √âtat ou province o√π la commande a √©t√© pass√©e.
- **Postal_Code** : Code postal de l'endroit o√π la commande a √©t√© pass√©e.
- **Region** : R√©gion g√©ographique (par exemple, Ouest, Sud, etc.).
- **Product_ID** : Identifiant unique pour chaque produit.
- **Category** : Cat√©gorie du produit (par exemple, Fournitures de bureau, Meubles, etc.).
- **Sub-Category** : Sous-cat√©gorie du produit (par exemple, √âtiquettes, Tables, etc.).
- **Product_Name** : Nom du produit.
- **Sales** : Montant total des ventes pour la commande.
- **Quantity** : Quantit√© du produit command√©.
- **Discount** : Rabais appliqu√© √† la commande.
- **Profit** : B√©n√©fice g√©n√©r√© par la commande.

> Il est important de noter que ces donn√©es contenir des erreurs et des donn√©es incorrectes qui n√©cessiteront un nettoyage et une correction avant de pouvoir √™tre analys√©es de mani√®re fiable üí°

**Example:**

|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|Order_ID|Order_Date|Ship_Date|Ship_Mode|Customer_ID|Customer_Name|Segment|Country|City|State|Postal_Code|Region|Product_ID|Category|Sub-Category|Product_Name|Sales|Quantity|Discount|Profit|
|CA-2016-138688|06/12/2016|06/16/2016|Deuxi√®me Classe|DV-13045|Darrin Van Huff|Entreprise|√âtats-Unis|Los Angeles|Californie|90036.0|Ouest|OFF-LA-10000240|Fournitures de bureau|√âtiquettes|√âtiquettes auto-adh√©sives pour machines √† √©crire|14,62 $|2|0%|6,87 $|
|US-2015-108966|10/11/2015|10/18/2015|Standard|SO-20335|Sean O'Donnell|Consommateur|√âtats-Unis|Fort Lauderdale|Floride|33311.0|Sud|FUR-TA-10000577|Meubles|Tables|Table rectangulaire mince de la s√©rie Bretford CR4500|957,58 $|5|45%|-383,03 $|

## Data Collecting:

La source de donn√©es que nous avons comprend 4 bases de donn√©es MySQL, un fichier CSV, un fichier texte (TXT) et un fichier JSON. J'ai besoin de collecter ces donn√©es et de les formater √† partir des 4 sources, donc j'utilise Pentaho Data Integration (PDI) √† cet effet.

![[Untitled.jpeg]]

Pentaho DI

> [!important]  
> Pentaho Data Integration (PDI) est une plateforme open source pour l'int√©gration de donn√©es, le nettoyage, la transformation et le chargement de donn√©es provenant de diverses sources. Elle offre une interface graphique conviviale pour cr√©er des flux de donn√©es et est largement utilis√©e pour l'analyse et le reporting dans les entreprises.  

Voila les fichier que j‚Äôai utliser:

![[Untitled 11.png|Untitled 11.png]]

Datasources files

Pour tableu de db:

![[Untitled 1 3.png|Untitled 1 3.png]]

Tables in Mysql db

Alors j‚Äôajoute tous les sources dans pentaho :

![[Untitled 2 3.png|Untitled 2 3.png]]

Reading Data From Mysql, txt, csv,json files

## Cleaning And Formatting:

Pour formater les donn√©es, j'utilise Pentaho. L'id√©e principale qui m'est venue d'abord est de nettoyer les donn√©es et de les combiner dans une seule table ou un seul ensemble de donn√©es volumineux pour ensuite les d√©couper en petites dimensions et tables de faits. Pour cela, j'utilise diverses techniques telles que les colonnes ordonn√©es (Orsecolumns) en utilisant les valeurs de s√©lection dans Pentaho, l'ajout de flux (append stream), des scripts JS pour v√©rifier d'autres √©l√©ments comme le format des dates et les enregistrements non valides.

Les transformations se sont d√©roul√©es comme suit :

![[Untitled 3 3.png|Untitled 3 3.png]]

Cleaning and formatting PDI

Ouput :

![[Untitled 4 3.png|Untitled 4 3.png]]

Output file

**Results Metrics:**

Nous avons commenc√© avec 30 000 lignes de donn√©es et actuellement nous en avons seulement 25 000 apr√®s le formatage et le nettoyage.

![[Untitled 5 3.png|Untitled 5 3.png]]

## Slicing et creation des tables fait et des tables des tables de dimensions:

### Model Mixte:

![[BI.png]]

Bas√© sur le sch√©ma de base de donn√©es que vous avez fourni, qui comprend des tables telles que `orders` (commandes), `products` (produits), `subcategories` (sous-cat√©gories), `categories` (cat√©gories), `customers` (clients), `locations` (emplacements) et `dates` (dates), vous semblez travailler dans un contexte de data warehousing ou de business intelligence o√π vous avez probablement un m√©lange de tables de faits et de dimensions.

Identifions les tables de faits et de dimensions en fonction de votre sch√©ma :

1. **Table de Faits :**
    - La table `orders` peut √™tre consid√©r√©e comme une table de faits car elle contient des valeurs num√©riques mesurables et additives telles que `Sales` (ventes), `Quantity` (quantit√©), `Discount` (remise) et `Profit` (profit). Les tables de faits stockent g√©n√©ralement des donn√©es transactionnelles et sont li√©es √† plusieurs tables de dimensions.
2. **Tables de Dimensions :**
    - Les tables `products` (produits), `subcategories` (sous-cat√©gories) et `categories` (cat√©gories) peuvent √™tre consid√©r√©es comme des tables de dimensions. Elles fournissent un contexte et des attributs descriptifs li√©s aux produits et √† leur cat√©gorisation. Les tables de dimensions sont g√©n√©ralement de taille plus petite et sont utilis√©es pour filtrer, regrouper et analyser les donn√©es de la table de faits.
    - Les tables `customers` (clients) et `locations` (emplacements) sont √©galement des tables de dimensions car elles fournissent des informations sur les clients et leurs emplacements, qui peuvent √™tre utilis√©es pour la segmentation et l'analyse.
    - La table `dates` (dates) peut √™tre une table de dimension temporelle qui fournit des attributs li√©s √† la date tels que `Date`, `DayOfWeek` (jour de la semaine), `Week` (semaine), `Month` (mois), `Quarter` (trimestre) et `Year` (ann√©e). Les tables de dimension temporelle sont cruciales pour l'analyse et le reporting bas√©s sur le temps.

### Data Slicing:

Pour cette √©tape, j'utilise Python et Pandas pour la cr√©ation de sous-tables, car j'ai rencontr√© quelques difficult√©s avec l'utilisation de Pentaho DI. Dans ce processus, j'adopte un mod√®le mixte o√π je cr√©e plusieurs tables √† partir du grand dataframe. La table de dimension principale est celle des commandes (order), tandis que les autres tables sont des tables de faits (fact tables).

![[Untitled 6 3.png|Untitled 6 3.png]]

> [!important]  
> Pandas is a Python library used for data manipulation and analysis. It provides data structures and tools for working with structured data, such as data frames, which are similar to tables in a database.  

**Slicing Script Example:**

![[Untitled 7 3.png|Untitled 7 3.png]]

Apr√®s le d√©coupage et la mise en forme des tables, voici le r√©sultat final qui sera export√© vers des fichiers CSV pour alimenter le data warehouse avec ces tables.

![[Untitled 8 2.png|Untitled 8 2.png]]

J'utilise Pentaho DI pour l'alimentation de chaque table comme suit :

![[Untitled 9 2.png|Untitled 9 2.png]]

Notre Base de donnees apres l‚Äôalimentation:

![[Untitled 10 2.png|Untitled 10 2.png]]

## Reporting & Visualization:

Bien s√ªr, pour cette √©tape, nous pouvons utiliser des logiciels tels que Power BI et Pentaho Analytics. Cependant, j'ai rencontr√© des probl√®mes de compatibilit√© avec mon appareil, c'est pourquoi j'ai d√©cid√© d'utiliser Matplotlib, et d'autres analyses avec pandas et le connecteur MySQL pour se connecter √† la base de donn√©es et l'utiliser avec pandas.

![[Untitled 1.jpeg]]

  

![[Untitled 11 2.png|Untitled 11 2.png]]

matplotlib

  

Cette example d‚Äôanalyse fournit des informations cl√©s pour l'entreprise en mati√®re de ventes et de rentabilit√©. En comprenant les ventes par cat√©gorie, le b√©n√©fice par segment, le mode d'exp√©dition le plus souvent associ√© √† des remises avantageuses, les ventes moyennes par cat√©gorie, le b√©n√©fice maximum par sous-cat√©gorie, les b√©n√©fices totaux par r√©gion et les meilleurs clients, l'entreprise peut prendre des d√©cisions strat√©giques. Ces donn√©es permettent d'identifier les domaines √† fort potentiel de croissance, d'optimiser les strat√©gies de tarification et de promotion, de cibler les segments de clients les plus rentables, et de maximiser la rentabilit√© globale de l'entreprise:

**Sales Per Category**

|   |   |   |
|---|---|---|
|index|Category|Sales|
|0|Furniture|1775353.5462|
|1|Office Supplies|1889360.964|
|2|Technology|2462358.425|

**Profit By Segment**

|   |   |   |
|---|---|---|
|index|Segment|Profit|
|0|Consumer|491099.35762|
|1|Corporate|299361.86303|
|2|Home Office|196626.02552|

Avg Discount By Ship Mode

|   |   |   |
|---|---|---|
|index|Ship_Mode|Discount|
|0|First Class|0.15815313056757443|
|1|Same Day|0.1485964935064935|
|2|Second Class|0.1439079817629179|
|3|Standard Class|0.1548402805453592|

Svg Sales By Category

|   |   |   |
|---|---|---|
|index|Category|Sales|
|0|Furniture|369.48044665972947|
|1|Office Supplies|122.77347222041718|
|2|Technology|463.54639024849394|

  

Max Profit By Subcategory

|   |   |   |
|---|---|---|
|index|Sub-Category|Profit|
|0|Accessories|829.3754|
|1|Appliances|793.716|
|2|Art|111.824|
|3|Binders|4946.37|
|4|Bookcases|374.6286|
|5|Chairs|770.352|
|6|Copiers|8399.976|
|7|Envelopes|204.0714|
|8|Fasteners|99.39215|
|9|Furnishings|272.792|
|10|Labels|126.3942|
|11|Machines|2799.984|
|12|Paper|352.296|
|13|Phones|1228.1787|
|14|Storage|792.2691|
|15|Supplies|327.506|
|16|Tables|610.8624|

Total Profit By Region

|   |   |   |
|---|---|---|
|index|Region|Profit|
|0|Central|188171.17452|
|1|East|298574.54086|
|2|South|155389.68965|
|3|West|344951.84114|

Top 10 Customers

|   |   |   |
|---|---|---|
|index|Customer_Name|Sales|
|708|Sean Miller|73558.302|
|753|Tamara Chand|57087.914000000004|
|638|Raymond Buch|45352.017|
|80|Becky Martin|45117.373999999996|
|780|Tom Ashbrook|43786.86|
|449|Ken Lonsdale|42056.663|
|693|Sanjit Chand|41545.682|
|6|Adrian Barton|41371.465000000004|
|340|Hunter Lopez|38473.114|
|694|Sanjit Engle|36040.694|

## Visualization:

![[Untitled 12.png]]

![[Untitled 13.png]]

![[Untitled 14.png]]

![[Untitled 15.png]]

![[Untitled 16.png]]

![[Untitled 17.png]]

![[Untitled 18.png]]

Ce graphique en nuage de points montre la relation entre les ventes et les b√©n√©fices, permettant de visualiser la corr√©lation entre ces deux variables dans les donn√©es.

![[Untitled 19.png]]

Ce boxplot montre la r√©partition des ventes selon les segments de clients, offrant une vue des variations et tendances des ventes par segment.

![[Untitled 20.png]]

Ce graphique lin√©aire repr√©sente l'√©volution des ventes au fil du temps, en utilisant la date des commandes comme variable temporelle, offrant ainsi une perspective temporelle sur les ventes.

![[Untitled 21.png]]

Ce violonplot illustre la distribution des b√©n√©fices selon le mode de livraison, mettant en √©vidence la variation des b√©n√©fices en fonction du mode de livraison utilis√©.

## OLAP

Pour utiliser un cube OLAP avec votre mod√®le de donn√©es Mixte dans Pentaho Schema Workbench, suivez ces √©tapes :

1. **Cr√©ation du Mod√®le de Donn√©es :**
    - j;ai utilise Pentaho Schema Workbench pour cr√©er un sch√©ma.
2. **D√©finition des Faits et des Mesures :**
3. **Cr√©ation du Cube OLAP :**
    - √Ä l'aide de Pentaho Schema Workbench, vous avez cr√©√© un cube OLAP en d√©finissant les dimensions n√©cessaires et en les reliant aux tables correspondantes de votre sch√©ma.
4. **Configuration des Hi√©rarchies :**
    - Pour chaque dimension, vous avez configur√© des hi√©rarchies afin d'organiser les donn√©es de mani√®re logique pour l'analyse (par exemple, hi√©rarchie de Date avec Ann√©e > Trimestre > Mois > Jour).
5. **Param√©trage des Propri√©t√©s du Cube :**
    
    configur√© les propri√©t√©s du cube telles que les agr√©gations, les formats de mesure, etc., pour optimiser les performances et la convivialit√© de l'analyse.
    
    ### Requets MDX:
    
    **Total des Ventes par Ann√©e :**
    
    - `SELECT [Measures].[Sales] ON COLUMNS, [Date].[Year].MEMBERS ON ROWS FROM [orders]`
    - **Total des Ventes par Cat√©gorie de Produit :**
    - `SELECT [Measures].[Sales] ON COLUMNS, [Category].[Category].MEMBERS ON ROWS FROM [orders]`
    - **Total des Ventes par Client et par Ann√©e :**
    
    `SELECT [Measures].[Sales] ON COLUMNS, [Customer].[Customer].MEMBERS ON ROWS, [Date].[Year].MEMBERS ON PAGES FROM [orders]`
    
    ## Resources:
    
    [https://www.kaggle.com/code/bahadir23/inventory-optimization-and-sustainability-analysis](https://www.kaggle.com/code/bahadir23/inventory-optimization-and-sustainability-analysis)
    
    [https://www.kaggle.com/datasets/winston56/fortune-500-data-2021](https://www.kaggle.com/datasets/winston56/fortune-500-data-2021)
    
    [https://www.kaggle.com/code/bahadir23/inventory-optimization-and-sustainability-analysis](https://www.kaggle.com/code/bahadir23/inventory-optimization-and-sustainability-analysis)
    
    ## Conclusion
    
    En conclusion, malgr√© les difficult√©s rencontr√©es avec certains outils de BI en raison de probl√®mes de compatibilit√©, j'ai r√©ussi √† mener √† bien le processus de nettoyage, de formatage et de cr√©ation de tables √† l'aide de Pentaho DI, Python avec Pandas, et Matplotlib pour la visualisation. Ces √©tapes ont permis de r√©duire les donn√©es initiales de 30 000 √† 25 000 lignes, et les tables r√©sultantes ont √©t√© export√©es avec succ√®s vers des fichiers CSV pour alimenter le data warehouse, et de fait visualization et reporting.
    
    # TP01
    
    **1-**
    
    - **Startup:** D√©marrage normal de la base de donn√©es.
    - **Startup nomount:** D√©marrage de la base de donn√©es sans monter les fichiers de donn√©es.
    - **Startup mount:** D√©marrage de la base de donn√©es et montage des fichiers de donn√©es, mais sans ouvrir la base.
    - **Startup force:** D√©marrage forc√© de la base de donn√©es, m√™me si elle est en mode incompatible.
    
    **2-**
    
    - **Shutdown normal:** Arr√™t normal de la base de donn√©es, avec fermeture propre des fichiers et transactions.
    - **Shutdown immediate:** Arr√™t imm√©diat de la base de donn√©es, sans attendre la fin des transactions en cours.
    - **Shutdown transactional:** Arr√™t de la base de donn√©es apr√®s la fin des transactions en cours.
    - **Shutdown abort:** Arr√™t brutal de la base de donn√©es, avec perte des donn√©es non valid√©es.
    
    **3-**
    
    ```Plain
    CONNECT / AS SYSDBA;
    SHUTDOWN NORMAL;
    ```
    
    4-
    
    ![[Untitled 2.jpeg]]
    
    5-
    
    ![[Untitled 3.jpeg]]
    
    6-
    
    ![[Untitled 4.jpeg]]
    
    7-
    
    ![[Untitled 5.jpeg]]
    
    10-
    
    ![[Untitled 6.jpeg]]
    
    11-
    
    ![[Untitled 7.jpeg]]
    
    12-
    
    ![[Untitled 8.jpeg]]
    
    13-
    
    ![[Untitled 9.jpeg]]
    
    ![[Untitled 22.png]]
    
    14-
    
    ![[Untitled 10.jpeg]]
    
    15-
    
    ![[Untitled 11.jpeg]]
    
    16-
    
    ![[Untitled 12.jpeg]]
    
    17-
    
    ![[Untitled 13.jpeg]]
    
    1-
    
    ![[Untitled 14.jpeg]]
    
    2-
    
    ![[Untitled 15.jpeg]]
    
    3-
    
    ![[Untitled 16.jpeg]]
    
    4-
    
    ![[Untitled 17.jpeg]]
    
    5-
    
    ![[Untitled 18.jpeg]]
    
    6-
    
    ![[Untitled 19.jpeg]]
    
    7-
    
    ![[Untitled 20.jpeg]]
    
    8-
    
    ![[Untitled 21.jpeg]]
    
    9-
    
    ![[Untitled 22.jpeg]]
    
    10-
    
    ![[Untitled 23.jpeg]]
    
    11-
    
    ![[Untitled 24.jpeg]]
    
    12-
    
    ![[Untitled 25.jpeg]]
    
    13-
    
    ![[Untitled 26.jpeg]]
    
    14-
    
    ![[Untitled 27.jpeg]]
    
    15-
    
    ![[Untitled 28.jpeg]]
    
    16-
    
    ![[Untitled 29.jpeg]]
    
    17-
    
    ![[Untitled 30.jpeg]]
    
    18-
    
    ![[Untitled 31.jpeg]]
    
    19-
    
    ![[Untitled 32.jpeg]]
    
    20-
    
    ![[Untitled 33.jpeg]]
    
    21-
    
    ![[Untitled 34.jpeg]]
    
    22-
    
    ![[Untitled 35.jpeg]]
    
    23-
    
    ![[Untitled 36.jpeg]]
    
    24-
    
    ![[Untitled 37.jpeg]]
    
    # TP2
    
    1-
    
    ![[Untitled 38.jpeg]]
    
    2-
    
    ![[Untitled 39.jpeg]]
    
    3-
    
    ![[Untitled 40.jpeg]]
    
    4-
    
    ![[Untitled 41.jpeg]]
    
    5-
    
    ![[Untitled 42.jpeg]]
    
    6-
    
    ![[Untitled 43.jpeg]]
    
    7-
    
    ![[Untitled 44.jpeg]]
    
    ![[Untitled 45.jpeg]]
    
    ![[Untitled 46.jpeg]]
    
    ![[Untitled 47.jpeg]]
    
    ![[Untitled 48.jpeg]]
    
    ![[Untitled 49.jpeg]]
    
    ![[Untitled 50.jpeg]]
    
    ![[Untitled 51.jpeg]]
    
    ![[Untitled 52.jpeg]]
    
    ![[Untitled 53.jpeg]]
    
    ![[Untitled 54.jpeg]]
    
    ![[Untitled 55.jpeg]]
    
    ![[Untitled 56.jpeg]]
    
    ![[Untitled 57.jpeg]]
    
    ![[Untitled 58.jpeg]]
    
    ![[Untitled 59.jpeg]]
    
    ![[Untitled 60.jpeg]]
    
    ![[Untitled 61.jpeg]]
    
    ![[Untitled 62.jpeg]]
    
    ![[Untitled 63.jpeg]]
    
    ![[Untitled 64.jpeg]]
    
    ![[Untitled 65.jpeg]]
    
    ![[Untitled 66.jpeg]]
    
    ![[Untitled 67.jpeg]]
    
    ![[Untitled 68.jpeg]]
    
    ![[Untitled 69.jpeg]]
    
    ![[Untitled 70.jpeg]]
    
    ![[Untitled 71.jpeg]]
    
    ![[Untitled 72.jpeg]]
    
    ![[Untitled 73.jpeg]]
    
    ![[Untitled 74.jpeg]]
    
    ![[Untitled 75.jpeg]]
    
    ![[Untitled 76.jpeg]]
    
    ![[Untitled 77.jpeg]]
    
    ![[Untitled 78.jpeg]]
    
    ![[Untitled 79.jpeg]]
    
    ![[Untitled 80.jpeg]]
    
    ![[Untitled 81.jpeg]]
    
    ![[Untitled 82.jpeg]]
    
    ![[Untitled 83.jpeg]]